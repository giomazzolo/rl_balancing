{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable_baselines3 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (2.2.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (2024.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from pandas->stable_baselines3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from pandas->stable_baselines3) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
      "^C\n",
      "Requirement already satisfied: ipykernel in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (6.29.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (8.21.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.7.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.14.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (306)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\envs\\stable_baselines\\lib\\site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "#!pip install stable-baselines3[extra]\n",
    "\n",
    "# -- Prerequisites install \n",
    "!pip3 install stable_baselines3 --user\n",
    "!pip3 install stable_baselines3 --user\n",
    "!pip3 install ipykernel --user\n",
    "!pip3 install tensorboard --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{hidden_layers_policy_network}\n",
      "3     randint\n",
      "4       Literal{4}\n",
      "5   Literal{1}\n",
      "6   Literal{2}\n",
      "7   Literal{3}\n",
      "8   Literal{4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A493191\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\policies.py:484: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x16e38658190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import stable_baselines3\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "\n",
    "#from stable_baselines3 import DQN,PPO,A2C\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "\n",
    "from hyperopt import hp,fmin,tpe\n",
    "import torch as th\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def set_up_model(params, env):\n",
    "    log_path = os.path.join('Training', 'Logs')\n",
    "    hidden_layers_policy_network = params['hidden_layers_policy_network']\n",
    "    size_hidden_layers_policy_network = params['size_hidden_layers_policy_network']\n",
    "    hidden_layers_value_network = params['hidden_layers_value_network']\n",
    "    size_hidden_layers_value_network = params['size_hidden_layers_value_network']\n",
    "\n",
    "    net_arch = [dict(pi=([size_hidden_layers_policy_network] * hidden_layers_policy_network),vf=([size_hidden_layers_value_network] * hidden_layers_value_network))]\n",
    "\n",
    "    activation_fn = {\"tanh\": th.nn.Tanh, \"relu\": th.nn.ReLU, \"elu\": th.nn.ELU, \"leaky_relu\": th.nn.LeakyReLU}[params['activation_fn']]\n",
    "\n",
    "    policy_kwargs = dict(net_arch=net_arch,\n",
    "                    ortho_init=params['ortho_init'],\n",
    "                    activation_fn=activation_fn)\n",
    "\n",
    "    batch_size = math.gcd(params['batch_size'],params['n_steps'])\n",
    "\n",
    "    model = PPO(\"MlpPolicy\",\n",
    "                env, \n",
    "                learning_rate=params['learning_rate'], \n",
    "                n_steps=params['n_steps'], \n",
    "                batch_size=batch_size, \n",
    "                n_epochs=params['n_epochs'], \n",
    "                gamma=params['gamma'], \n",
    "                gae_lambda=params['gae_lambda'], \n",
    "                clip_range=params['clip_range'], \n",
    "                ent_coef=params['ent_coef'], \n",
    "                vf_coef=params['vf_coef'], \n",
    "                max_grad_norm=params['max_grad_norm'],\n",
    "                policy_kwargs=policy_kwargs,\n",
    "                verbose=0, \n",
    "                tensorboard_log=log_path,\n",
    "                device='cuda')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "space = {\n",
    "        'learning_rate': 5e-6,\n",
    "        'n_steps': 128,\n",
    "        'batch_size': 128,\n",
    "        'n_epochs': 10,\n",
    "        'gamma': 0.99,\n",
    "        'gae_lambda': 0.9,\n",
    "        'clip_range': 0.2,\n",
    "        'ent_coef': 0,\n",
    "        'vf_coef': 0.5,\n",
    "        'max_grad_norm': 0.5,\n",
    "        'lr_schedule': 'linear',\n",
    "        'hidden_layers_policy_network': 2,\n",
    "        'size_hidden_layers_policy_network': 128,\n",
    "        'hidden_layers_value_network': 2,\n",
    "        'size_hidden_layers_value_network': 128,\n",
    "        'ortho_init': False,\n",
    "        'activation_fn': \"relu\"\n",
    "    }\n",
    "\n",
    "\n",
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = BatteryEnv()\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "\n",
    "check_env(env, warn=True)\n",
    "\n",
    "print(hp.choice('hidden_layers_policy_network', [1,2,3,4]))\n",
    "\n",
    "model = set_up_model(space,env)\n",
    "\n",
    "model.learn(total_timesteps=1000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STABLEBASELINES TESTBED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery env \n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from typing import Optional, Union\n",
    "\n",
    "#class BatteryEnv(gym.Env[np.ndarray, Union[int, np.ndarray]]):\n",
    "\n",
    "class BatteryEnv(gym.Env):\n",
    "\n",
    "   def __init__(self, nr_batteries, render_mode: Optional[str] = None):\n",
    "      super().__init__()\n",
    "      #self.zk = 9.8  # = SOC\n",
    "      #self.hk = 1.0  # = hysteresis state\n",
    "      #self.t = 1.0   # = temperature\n",
    "      #self.vk = 1.0\n",
    "      #self.rck = 1.0 # = Current through paralel resistor\n",
    "\n",
    "      #     action_high = np.array(\n",
    "      #       [\n",
    "      #       #   10,         #min= 0, max= 10       Voltage (v) - vk\n",
    "      #          80,        #min= 0, max= 100      SOC - zk\n",
    "      #          80,        #min= 0, max= 100      SOC - zk\n",
    "      #       #   150,        #min= -30, max= 150    Temperature  - t\n",
    "      #       #   1,          #min= -1, max= 1       Hysteresis state - hk\n",
    "      #       #   100,        #min= -100, max= 100   Current through paralel resistor - rck\n",
    "      #       #   33459,      # time \n",
    "      #       #   np.finfo(np.float32).max,   #min= Inf, max= Inf\n",
    "      #    ],\n",
    "      #    dtype=np.float64,\n",
    "      # )\n",
    "      \n",
    "      #...\n",
    "\n",
    "      self.env_id = \"Battery v0.3\"\n",
    "      self.num_envs = 1\n",
    "      \n",
    "      # SOHt​=f(SOCt​,CRt​) - soh as function of charge rate and soc\n",
    "      # SOHt​=SOHt−1​−k×CRt​\n",
    "      self.degradation_coeficient = 0.2\n",
    "\n",
    "      self.soc_threshold_upper = 85\n",
    "      self.soc_threshold_lower = 15\n",
    "\n",
    "      self.episode_time = 0\n",
    "\n",
    "      self.nr_batteries = nr_batteries\n",
    "\n",
    "\n",
    "\n",
    "      high = np.array(\n",
    "            [\n",
    "               100,        #min= 0, max= 100      SOC - zk\n",
    "               100,        #min= 0, max= 100      SOC - zk\n",
    "         ],\n",
    "         dtype=np.float32,\n",
    "      )\n",
    "\n",
    "      low = np.array(\n",
    "            [\n",
    "               0,\n",
    "               0,\n",
    "         ],\n",
    "         dtype=np.float32,\n",
    "      )\n",
    "\n",
    "\n",
    "      self.action_space = gym.spaces.Box(-1, 1, (self.nr_batteries,), dtype=np.float32) # cell1,cell2,cell3... and voltage\n",
    "      self.observation_space = gym.spaces.Box(0, 100, (self.nr_batteries,), dtype=np.float32)\n",
    "\n",
    "      self.state = None\n",
    "      self.steps_beyond_terminated = None\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "   def step(self, action):\n",
    "      err_msg = f\"{action!r} ({type(action)}) invalid\"\n",
    "      assert self.action_space.contains(action), err_msg\n",
    "      assert self.state is not None, \"Call reset before using step method.\"\n",
    "\n",
    "\n",
    "      battery_current_values = get_converted_action(action)\n",
    "\n",
    "      #vk, zk, t, hk, rck, time = self.state\n",
    "\n",
    "\n",
    "      # discharge until 15, and 85 limilits\n",
    "      #print(action)\n",
    "\n",
    "\n",
    "      self.episode_time += 1\n",
    "      passed_threshold = False\n",
    "      exiting_observation_space = False\n",
    "\n",
    "      self.state = np.subtract(self.state, battery_current_values)         \n",
    "\n",
    "      for soc in self.state:\n",
    "\n",
    "         if (soc < self.soc_threshold_lower or soc > self.soc_threshold_upper):\n",
    "            passed_threshold = True\n",
    "         if (soc < 0 or soc > 100):\n",
    "            # EXITED OBSERVATION SPACE. Terminate immediatley.\n",
    "            soc = 0.0\n",
    "            exiting_observation_space = True\n",
    "            print(\"//////// EXITED OBSERVATION SPACE BOUNDS ////////  \"  + str(soc))\n",
    "            #return np.array(self.state , dtype=np.float32), -10000000000000, True, False, {}\n",
    "\n",
    "\n",
    "      if exiting_observation_space:\n",
    "         # Terminate. Apply penalty.\n",
    "         return np.array(self.state , dtype=np.float32), -100000, True, False, {}\n",
    "\n",
    "\n",
    "\n",
    "      # right now the reward in only based on if the variables fall out of bounds \n",
    "      # passed_thr = bool(\n",
    "      #    soc0 < self.soc_threshold_lower\n",
    "      #    or soc0 > self.soc_threshold_upper\n",
    "      #    or soc1 < self.soc_threshold_lower\n",
    "      #    or soc1 > self.soc_threshold_upper\n",
    "      #    # time doesnt really make sense here for now\n",
    "      #    #or time < 0\n",
    "      #    #or time > 33458\n",
    "      # )\n",
    "\n",
    "\n",
    "      terminated = False\n",
    "\n",
    "      reward = 0\n",
    "      if not passed_threshold and self.episode_time == 128:\n",
    "         # Timeout\n",
    "         self.episode_time = 0\n",
    "         # reward = 0\n",
    "         reward = compute_ballancing_reward(self.state, False)\n",
    "         terminated = True\n",
    "      elif not passed_threshold:\n",
    "         # Apply cost(reward)\n",
    "         # if (math.isclose(soc0, soc1, abs_tol=1)):\n",
    "         #    reward = 0\n",
    "         # else:\n",
    "         reward = compute_ballancing_reward(self.state, False)\n",
    "\n",
    "      \n",
    "      elif passed_threshold:\n",
    "         # Batteries drained! Terminated.\n",
    "         self.steps_beyond_terminated = 0\n",
    "         \n",
    "         #terminated = True\n",
    "         #self.episode_time = 0\n",
    "         reward = -10000\n",
    "\n",
    "         #if self.episode_time == 128:\n",
    "         terminated = True\n",
    "\n",
    "      # Sanity check. Do not continue steps after termination. Call reset first.\n",
    "      # if self.steps_beyond_terminated > 0:\n",
    "      #    print(\n",
    "      #       \"You are calling 'step()' even though this \"\n",
    "      #       \"environment has already returned terminated = True. You \"\n",
    "      #       \"should always call 'reset()' once you receive 'terminated = \"\n",
    "      #       \"True' -- any further steps are undefined behavior.\"\n",
    "      #    )\n",
    "      #    self.steps_beyond_terminated += 1\n",
    "      #    reward = 0.0\n",
    "\n",
    "\n",
    "      if self.render_mode == \"human\":\n",
    "         self.render()\n",
    "      \n",
    "      return np.array(self.state, dtype=np.float32), float(reward), terminated, False, {}\n",
    "   \n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "   def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,):\n",
    "        \n",
    "\n",
    "         super().reset(seed=seed)\n",
    "         # Note that if you use custom reset bounds, it may lead to out-of-bound\n",
    "         # state/observations.\n",
    "         #high = utils.maybe_parse_reset_bounds(\n",
    "         #    options, -0.05, 0.05  # default low\n",
    "         #)  # default high\n",
    "\n",
    "\n",
    "         self.episode_time = 0\n",
    "\n",
    "         #definition of an episode: 1 whole run of the matlab script\n",
    "         #                               OR\n",
    "         #                          1 segment of it?\n",
    "\n",
    "         self.state = self.np_random.uniform(low=15, high=85, size=(self.nr_batteries,))\n",
    "\n",
    "         self.steps_beyond_terminated = None\n",
    "\n",
    "         if self.render_mode == \"human\":\n",
    "               self.render()\n",
    "         return np.array(self.state, dtype=np.float32), {}\n",
    "\n",
    "\n",
    "\n",
    "def compute_ballancing_reward(socs, should_print):\n",
    "\n",
    "   \n",
    "   #cost as distance between 2 numbers\n",
    "   #reward = -pow(soc0 - soc1, 2)\n",
    "   \n",
    "   #cost as standard deviation\n",
    "   reward = -np.std(socs, dtype=np.float32)\n",
    "\n",
    "   # if(should_print):\n",
    "   #    print( \"SOC Mean: \" + str(mean) +  \"    ---- SOC1 Difference    \"  + str(difference1)  +  \"    ----   SOC2 Difference    \"  + str(difference2))\n",
    "\n",
    "   return reward\n",
    "\n",
    "\n",
    "def get_converted_action(action):\n",
    "   current_values = []\n",
    "   for current in action:\n",
    "      shifted_value = (current + 1.0) * 5.0  #from [-1, 1] to [0, 10]\n",
    "      current_values.append(shifted_value)\n",
    "\n",
    "   return current_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def plot_step(episode_number, state, action, reward, show_result=False):\n",
    "    \n",
    "    fig = plt.figure(1)\n",
    "\n",
    "    actions_t = torch.tensor(action, dtype=torch.float)\n",
    "    rewards_t = torch.tensor(reward, dtype=torch.float)\n",
    "\n",
    "    plt.title('Episode ' + str(episode_number))\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('SOC & Actions')\n",
    "\n",
    "\n",
    "\n",
    "    # Plot SOCs\n",
    "    soc0 = []\n",
    "    soc1 = []\n",
    "    for st in state:\n",
    "        # states_t = torch.tensor(st, dtype=torch.float)\n",
    "        # plt.plot(states_t.cpu().squeeze().numpy(), label='State ' + str(st))\n",
    "\n",
    "        soc0.append(st[0][0].item())\n",
    "        soc1.append(st[0][1].item())\n",
    "    \n",
    "    plt.plot(soc0, label='soc0')\n",
    "    plt.plot(soc1, label='soc1')\n",
    "\n",
    "\n",
    "\n",
    "    # Plot actions as indvidual points\n",
    "    action_array = np.multiply(actions_t.numpy(), 10)   # multiply action values by 10 for better display on graph\n",
    "    plt.plot(action_array, 'bo', markersize=0.4, label='Action')\n",
    "    line_nr = 0\n",
    "\n",
    "    # Plot action value as text above point\n",
    "    # for line in action_array:\n",
    "    #     plt.text(line_nr, line+1.8, str(int(line)), horizontalalignment='center', size='small', color='black')\n",
    "    #     line_nr = line_nr + 1 \n",
    "\n",
    "\n",
    "    # Plot actions as single point average\n",
    "    # Take 100 steps average and plot the average action for that period\n",
    "    # if len(actions_t) >= 10:\n",
    "    #     means = actions_t.unfold(0, 10, 1).mean(1).view(-1)\n",
    "    #     means = torch.cat((torch.zeros(9), means))\n",
    "    #     plt.plot(means.numpy(), 'go', markersize=1, label='Action')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    # Plot rewards\n",
    "    # Reduces displayed rewards by an order of 10 to fit within the graph\n",
    "    fig2 = plt.figure(2)\n",
    "    plt.title('Episode ' + str(episode_number))\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Reward')\n",
    "    #plt.plot(np.divide(rewards_t.numpy(), 10), label='Reward')\n",
    "    plt.plot(rewards_t.numpy(), label='Reward')\n",
    "\n",
    "    # add legend with labels\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.pause(0.0001)  # pause a bit so that plots are updated\n",
    "    #if is_ipython:\n",
    "    if not show_result:\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    else:\n",
    "        display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT FUNCTIONAL\n",
    "\n",
    "class TimeLimitWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    :param env: (gym.Env) Gym environment that will be wrapped\n",
    "    :param max_steps: (int) Max number of steps per episode\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, max_steps=100):\n",
    "        # Call the parent constructor, so we can access self.env later\n",
    "        super(TimeLimitWrapper, self).__init__(env)\n",
    "        self.max_steps = max_steps\n",
    "        # Counter of steps per episode\n",
    "        self.current_step = 0\n",
    "\n",
    "        # PLOT CODE\n",
    "        # self.episode_durations = []\n",
    "        self.current_episode_states = []\n",
    "        self.current_episode_actions = []\n",
    "        self.current_episode_rewards = []\n",
    "\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Reset the environment\n",
    "        \"\"\"\n",
    "        # Reset the counter\n",
    "        self.current_step = 0\n",
    "        print(\"dsdsdsdsds\")\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        :param action: ([float] or int) Action taken by the agent\n",
    "        :return: (np.ndarray, float, bool, bool, dict) observation, reward, is the episode over?, additional informations\n",
    "        \"\"\"\n",
    "        self.current_step += 1\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        print(\"dsdsdsdsds\")\n",
    "\n",
    "        # PLOT CODE\n",
    "        self.current_episode_states.append(self.env.state)\n",
    "        self.current_episode_actions.append(action[0].item())\n",
    "        self.current_episode_rewards.append(reward)\n",
    "\n",
    "        plot_step(1, self.current_episode_states,  self.current_episode_actions,  self.current_episode_rewards)\n",
    "\n",
    "        # Overwrite the truncation signal when when the number of steps reaches the maximum\n",
    "        if self.current_step >= self.max_steps:\n",
    "            truncated = True\n",
    "        return obs, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "\n",
    "#from stable_baselines3 import DQN,PPO,A2C\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "\n",
    "from hyperopt import hp,fmin,tpe\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "\n",
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            # print(x[-100:])\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "                    #print (self.training_env.state)\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gymnasium[box2d]\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "from stable_baselines3.common.vec_env.vec_monitor import VecMonitor\n",
    "\n",
    "\n",
    "\n",
    "# Create log dir\n",
    "log_dir = \"./tmp/gym/ppotest/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create and wrap the environment\n",
    "#env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "env = BatteryEnv(5, False)\n",
    "# env = gym.wrappers.TimeLimit(env, max_episode_steps = 500)\n",
    "# env = gym.wrappers.AutoResetWrapper(env)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    check_env(env)\n",
    "\n",
    "# OrderEnforcing -- throw error if step is caled before reset\n",
    "\n",
    "#end = TimeLimitWrapper(env, max_steps=50)   -- NOT FUNCTUONAL ON THIS IMPL\n",
    "# Logs will be saved in log_dir/monitor.csv \n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecNormalize(env, norm_reward=True, norm_obs=False)\n",
    "env = VecMonitor(env, log_dir) #monitor for vec environments\n",
    "\n",
    "#env = Monitor(env, log_dir) #monitor for raw environments\n",
    "\n",
    "\n",
    "\n",
    "# run random env tests tomake sure everything is in order\n",
    "# for i in range(0, 100):\n",
    "#     check_env(env)\n",
    "\n",
    "\n",
    "#env = gym.wrappers.RecordEpisodeStatistics(env, 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C, SAC, PPO, TD3\n",
    "\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy, BasePolicy, MultiInputActorCriticPolicy\n",
    "\n",
    "\n",
    "print(\"Is CUDA enabled?\", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Create action noise because TD3 and DDPG use a deterministic policy\n",
    "#n_actions = env.action_space.shape[-1]\n",
    "#action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# Create the callback: check every 1000 steps\n",
    "#callback = SaveOnBestTrainingRewardCallback(check_freq=512, log_dir=log_dir)\n",
    "\n",
    "# Create RL model\n",
    "#model = PPO('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./ppo_tensorboard_log/\", learning_rate=1e-4, gamma=0.20)\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    'learning_rate': 0.0003,  # Learning rate\n",
    "    'n_steps': 2048,  # Number of steps per epoch\n",
    "    'batch_size': 256,  # Minibatch size for SGD\n",
    "    'ent_coef': 0.01,  # Entropy coefficient for exploration\n",
    "    # 'gamma': 0.99,  # Discount factor\n",
    "    'gae_lambda': 0.95,  # Lambda coefficient (controls bias-variance trade-off in advantage estimation)\n",
    "    'clip_range': 0.2,  # Clip range for PPO clip loss\n",
    "    'n_epochs': 4,  # Number of epochs per update\n",
    "    'max_grad_norm': 0.5,  # Max norm of gradients\n",
    "    'vf_coef': 0.5,  # Value function coefficient in the total loss\n",
    "    # 'use_sde': False,  # Whether to use Squashed Diagonal Gaussian policy\n",
    "    # 'sde_sample_freq': -1,  # Sample frequency for SDE when `use_sde=True`\n",
    "}\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./ppo_tensorboard_log/\", policy_kwargs={'net_arch':dict(pi=[256, 256, 256],\n",
    "                                                                                                                                 vf=[256, 256, 256])}, **hyperparameters)\n",
    "\n",
    "\n",
    "\n",
    "callback = EvalCallback(env, log_path=log_dir, n_eval_episodes= 20, eval_freq= 20*128, callback_after_eval=SaveOnBestTrainingRewardCallback(check_freq=1, log_dir=log_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2560, episode_reward=-2.09 +/- 0.00\n",
      "Episode length: 2.80 +/- 1.86\n",
      "New best mean reward!\n",
      "Num timesteps: 2560\n",
      "Best mean reward: -inf - Last mean reward per episode: -2.09\n",
      "Saving new best model to ./tmp/gym/ppotest/best_model.zip\n",
      "Eval num_timesteps=5120, episode_reward=-2.11 +/- 0.00\n",
      "Episode length: 2.60 +/- 1.24\n",
      "Num timesteps: 5120\n",
      "Best mean reward: -2.09 - Last mean reward per episode: -2.11\n",
      "Eval num_timesteps=7680, episode_reward=-2.14 +/- 0.01\n",
      "Episode length: 3.30 +/- 2.26\n",
      "Num timesteps: 7680\n",
      "Best mean reward: -2.09 - Last mean reward per episode: -2.14\n",
      "Eval num_timesteps=10240, episode_reward=-2.17 +/- 0.01\n",
      "Episode length: 6.10 +/- 4.07\n",
      "Num timesteps: 10240\n",
      "Best mean reward: -2.09 - Last mean reward per episode: -2.16\n",
      "Eval num_timesteps=12800, episode_reward=-2.20 +/- 0.01\n",
      "Episode length: 5.90 +/- 3.60\n",
      "Num timesteps: 12800\n",
      "Best mean reward: -2.09 - Last mean reward per episode: -2.19\n",
      "Eval num_timesteps=15360, episode_reward=-2.22 +/- 0.01\n",
      "Episode length: 6.20 +/- 3.98\n",
      "Num timesteps: 15360\n",
      "Best mean reward: -2.09 - Last mean reward per episode: -2.22\n",
      "Eval num_timesteps=17920, episode_reward=-2.26 +/- 0.01\n",
      "Episode length: 8.75 +/- 4.70\n",
      "Num timesteps: 17920\n",
      "Best mean reward: -2.09 - Last mean reward per episode: -2.25\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common import results_plotter\n",
    "\n",
    "#print(model.policy)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(40000000000000000), callback=callback)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results(\n",
    "    [log_dir], 1e6, results_plotter.X_TIMESTEPS, \"PPO - Env: Battery\"\n",
    ")\n",
    "\n",
    "\n",
    "# reduce samples: callback: eval callback episodes and eval_freq\n",
    "#                 env: n_steps, n_epochs, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m results_plotter\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Helper from the library\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m results_plotter\u001b[38;5;241m.\u001b[39mplot_results(\n\u001b[0;32m      5\u001b[0m     [log_dir], \u001b[38;5;241m1e7\u001b[39m, results_plotter\u001b[38;5;241m.\u001b[39mX_TIMESTEPS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO - Env: Battery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\results_plotter.py:122\u001b[0m, in \u001b[0;36mplot_results\u001b[1;34m(dirs, num_timesteps, x_axis, task_name, figsize)\u001b[0m\n\u001b[0;32m    120\u001b[0m     data_frames\u001b[38;5;241m.\u001b[39mappend(data_frame)\n\u001b[0;32m    121\u001b[0m xy_list \u001b[38;5;241m=\u001b[39m [ts2xy(data_frame, x_axis) \u001b[38;5;28;01mfor\u001b[39;00m data_frame \u001b[38;5;129;01min\u001b[39;00m data_frames]\n\u001b[1;32m--> 122\u001b[0m plot_curves(xy_list, x_axis, task_name, figsize)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\results_plotter.py:85\u001b[0m, in \u001b[0;36mplot_curves\u001b[1;34m(xy_list, x_axis, title, figsize)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mplot the curves\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m:param figsize: Size of the figure (width, height)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(title, figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[1;32m---> 85\u001b[0m max_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(xy[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m xy_list)\n\u001b[0;32m     86\u001b[0m min_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(xy_list):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\results_plotter.py:85\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mplot the curves\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m:param figsize: Size of the figure (width, height)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(title, figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[1;32m---> 85\u001b[0m max_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(xy[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m xy_list)\n\u001b[0;32m     86\u001b[0m min_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(xy_list):\n",
      "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3.common import results_plotter\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results(\n",
    "    [log_dir], 1e7, results_plotter.X_TIMESTEPS, \"PPO - Env: Battery\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def moving_average(values, window):\n",
    "    \"\"\"\n",
    "    Smooth values by doing a moving average\n",
    "    :param values: (numpy array)\n",
    "    :param window: (int)\n",
    "    :return: (numpy array)\n",
    "    \"\"\"\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, \"valid\")\n",
    "\n",
    "\n",
    "def plot_results(log_folder, title=\"Learning Curve\"):\n",
    "    \"\"\"\n",
    "    plot the results\n",
    "\n",
    "    :param log_folder: (str) the save location of the results to plot\n",
    "    :param title: (str) the title of the task to plot\n",
    "    \"\"\"\n",
    "    x, y = ts2xy(load_results(log_folder), \"timesteps\")\n",
    "    y = moving_average(y, window=50)\n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y) :]\n",
    "\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"Number of Timesteps\")\n",
    "    plt.ylabel(\"Rewards\")\n",
    "    plt.title(title + \" Smoothed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "v cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_results(log_dir)\n",
      "Cell \u001b[1;32mIn[12], line 23\u001b[0m, in \u001b[0;36mplot_results\u001b[1;34m(log_folder, title)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mplot the results\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m:param log_folder: (str) the save location of the results to plot\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m:param title: (str) the title of the task to plot\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m x, y \u001b[38;5;241m=\u001b[39m ts2xy(load_results(log_folder), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m y \u001b[38;5;241m=\u001b[39m moving_average(y, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Truncate x\u001b[39;00m\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(y) :]\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mmoving_average\u001b[1;34m(values, window)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mSmooth values by doing a moving average\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m:param values: (numpy array)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m:param window: (int)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m:return: (numpy array)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1.0\u001b[39m, window) \u001b[38;5;241m/\u001b[39m window\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconvolve(values, weights, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\A493191\\AppData\\Local\\anaconda3\\envs\\stable_baselines\\Lib\\site-packages\\numpy\\core\\numeric.py:833\u001b[0m, in \u001b[0;36mconvolve\u001b[1;34m(a, v, mode)\u001b[0m\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 833\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m multiarray\u001b[38;5;241m.\u001b[39mcorrelate(a, v[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], mode)\n",
      "\u001b[1;31mValueError\u001b[0m: v cannot be empty"
     ]
    }
   ],
   "source": [
    "\n",
    "plot_results(log_dir)\n",
    "\n",
    "\n",
    "# study value and policy more\n",
    "# view episides during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62.385784 55.54666  46.728676 21.199192 64.53223 ]]  ACTION:[2.431714  6.7046204 0.        0.        1.3849819]  >>>> \n",
      "[[59.95407  48.84204  46.728676 21.199192 63.147243]]  REWARD:  [-0.00561348]   \n",
      "[[59.95407  48.84204  46.728676 21.199192 63.147243]]  ACTION:[8.361048  8.427318  1.7917285 0.        0.       ]  >>>> \n",
      "[[51.593025 40.414722 44.936947 21.199192 63.147243]]  REWARD:  [-0.00525429]   \n",
      "[[51.593025 40.414722 44.936947 21.199192 63.147243]]  ACTION:[0.        0.        1.2301415 0.        4.1752996]  >>>> \n",
      "[[51.593025 40.414722 43.706806 21.199192 58.971943]]  REWARD:  [-0.00483628]   \n",
      "[[51.593025 40.414722 43.706806 21.199192 58.971943]]  ACTION:[3.3717065  0.12474239 0.         0.         4.0289235 ]  >>>> \n",
      "[[48.221317 40.289978 43.706806 21.199192 54.94302 ]]  REWARD:  [-0.00430969]   \n",
      "[[48.221317 40.289978 43.706806 21.199192 54.94302 ]]  ACTION:[2.5812187 2.9634185 0.        0.        6.3251166]  >>>> \n",
      "[[45.6401   37.32656  43.706806 21.199192 48.617905]]  REWARD:  [-0.00371227]   \n",
      "[[45.6401   37.32656  43.706806 21.199192 48.617905]]  ACTION:[5.3804064 6.6673355 0.        0.        0.9946832]  >>>> \n",
      "[[40.259693 30.659225 43.706806 21.199192 47.623222]]  REWARD:  [-0.00363328]   \n",
      "[[40.259693 30.659225 43.706806 21.199192 47.623222]]  ACTION:[0.        0.        5.302756  0.        3.0616255]  >>>> \n",
      "[[40.259693 30.659225 38.40405  21.199192 44.561596]]  REWARD:  [-0.00313087]   \n",
      "[[40.259693 30.659225 38.40405  21.199192 44.561596]]  ACTION:[ 0.73543847  0.         10.          0.          0.        ]  >>>> \n",
      "[[39.524254 30.659225 28.404049 21.199192 44.561596]]  REWARD:  [-0.00314023]   \n",
      "[[39.524254 30.659225 28.404049 21.199192 44.561596]]  ACTION:[10.         1.2877212  2.7514126  0.         6.983552 ]  >>>> \n",
      "[[29.524254 29.371504 25.652637 21.199192 37.578045]]  REWARD:  [-0.00204815]   \n",
      "[[29.524254 29.371504 25.652637 21.199192 37.578045]]  ACTION:[0.11176407 0.         0.         0.         0.        ]  >>>> \n",
      "[[29.41249  29.371504 25.652637 21.199192 37.578045]]  REWARD:  [-0.00204687]   \n",
      "[[29.41249  29.371504 25.652637 21.199192 37.578045]]  ACTION:[6.7442884 1.1910564 0.        0.        8.819937 ]  >>>> \n",
      "[[22.668201 28.180449 25.652637 21.199192 28.758106]]  REWARD:  [-0.0011279]   \n",
      "[[22.668201 28.180449 25.652637 21.199192 28.758106]]  ACTION:[0.        1.8318715 0.        0.        0.       ]  >>>> \n",
      "[[22.668201 26.348577 25.652637 21.199192 28.758106]]  REWARD:  [-0.00102197]   \n",
      "[[22.668201 26.348577 25.652637 21.199192 28.758106]]  ACTION:[0.         0.04528582 3.6254945  0.         0.        ]  >>>> \n",
      "[[22.668201 26.303291 22.027142 21.199192 28.758106]]  REWARD:  [-0.00109087]   \n",
      "[[22.668201 26.303291 22.027142 21.199192 28.758106]]  ACTION:[0.        4.5858912 0.        0.        0.       ]  >>>> \n",
      "[[22.668201 21.7174   22.027142 21.199192 28.758106]]  REWARD:  [-0.00105667]   \n",
      "[[22.668201 21.7174   22.027142 21.199192 28.758106]]  ACTION:[2.0424912 0.        0.        0.        0.       ]  >>>> \n",
      "[[20.625711 21.7174   22.027142 21.199192 28.758106]]  REWARD:  [-0.0011332]   \n",
      "[[20.625711 21.7174   22.027142 21.199192 28.758106]]  ACTION:[0.        0.        0.        0.9125036 1.185742 ]  >>>> \n",
      "[[20.625711 21.7174   22.027142 20.286688 27.572365]]  REWARD:  [-0.00100403]   \n",
      "[[20.625711 21.7174   22.027142 20.286688 27.572365]]  ACTION:[0. 0. 0. 0. 0.]  >>>> \n",
      "[[20.625711 21.7174   22.027142 20.286688 27.572365]]  REWARD:  [-0.00100403]   \n",
      "[[20.625711 21.7174   22.027142 20.286688 27.572365]]  ACTION:[0.        0.        0.        2.6706884 0.       ]  >>>> \n",
      "[[20.625711 21.7174   22.027142 17.616001 27.572365]]  REWARD:  [-0.00122684]   \n",
      "FINAL: \n",
      "[11.640283 20.197248 22.027142 17.616001 25.783684]       ACTION:\n",
      "[8.985428214073181, 1.5201511979103088, 0.0, 0.0, 1.7886802554130554]\n",
      "REWARD:  -3.796843\n",
      "EPISODE TOTAL REWARD: -3.843233974184841\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def test_trained_model():\n",
    "    obs = model.get_env().reset()\n",
    "    episode_reward = 0\n",
    "\n",
    "    obsArray = []\n",
    "\n",
    "    while True:\n",
    "        obsArray.append(obs)\n",
    "        action, _states = model.predict(obs)\n",
    "        oldObs = obs\n",
    "        obs, rewards, done, info = model.get_env().step(action)\n",
    "        episode_reward += rewards.squeeze()\n",
    "\n",
    "        if not done:\n",
    "            print(str(oldObs) + \"  ACTION:\" + str(get_converted_action(action)[0]) + \"  >>>> \")\n",
    "            print(str(obs) + \"  REWARD:  \"  + str(rewards) + \"   \")\n",
    "        else:\n",
    "            info_item = info.pop()\n",
    "            print(\"FINAL: \")\n",
    "            print(str(info_item.get('terminal_observation'))  + \"       ACTION:\" )\n",
    "            print(str(str(get_converted_action(action.flatten()))))\n",
    "            print(\"REWARD:  \" + str(rewards[0]))\n",
    "            print(\"EPISODE TOTAL REWARD: \" + str(episode_reward))\n",
    "\n",
    "            # plot final model\n",
    "            fig = plt.figure(1)\n",
    "\n",
    "            data_np = np.array(obsArray)\n",
    "\n",
    "            plt.xlabel('Step')\n",
    "            plt.ylabel('SOC')\n",
    "            print(\"------------------------------------------------------\")\n",
    "            plt.ylim([-10, 100])\n",
    "\n",
    "\n",
    "            i = 0\n",
    "            for soc in data_np.T:\n",
    "                plt.plot(np.arange(start=0, stop=len(data_np), step=1), soc.flatten(), label=\"soc\"+str(i))\n",
    "                i += 1\n",
    "\n",
    "            plt.legend()\n",
    "            #plt.pause(3)\n",
    "\n",
    "            obsArray = []\n",
    "            episode_reward = 0\n",
    "            obs = model.get_env().reset()\n",
    "\n",
    "            #time.sleep(0.5)\n",
    "            break\n",
    "\n",
    "\n",
    "# def test_paralel_model():\n",
    "\n",
    "#     env = BatteryEnv(5, False)\n",
    "#     env = DummyVecEnv([lambda: env])\n",
    "\n",
    "#     # intialized here\n",
    "#     obs = env.reset()\n",
    "    \n",
    "#     episode_reward = 0\n",
    "#     obsArray = []\n",
    "\n",
    "#     while True:\n",
    "#         action, _states = model.predict(obs)\n",
    "#         oldObs = obs\n",
    "#         obs, rewards, done, info = model.get_env().step(action)\n",
    "#         episode_reward += rewards.squeeze()\n",
    "\n",
    "#         print(str(oldObs) + \"  ACTION:\" + str(action) + \"  >>>> \")\n",
    "\n",
    "\n",
    "#         if not done:\n",
    "#             print(str(oldObs) + \"  ACTION:\" + str(action) + \"  >>>> \")\n",
    "#             print(str(obs) + \"  REWARD:  \"  + str(rewards) + \"   \")\n",
    "#         else:\n",
    "#             info_item = info.pop()\n",
    "#             print(\"FINAL: \")\n",
    "#             print(str(info_item.get('terminal_observation'))  + \"       ACTION:\" )\n",
    "#             print(str(str(action.flatten())))\n",
    "#             print(\"REWARD:  \" + str(rewards[0]))\n",
    "#             print(\"EPISODE TOTAL REWARD: \" + str(episode_reward))\n",
    "\n",
    "#             # plot final model\n",
    "#             fig = plt.figure(1)\n",
    "\n",
    "#             data_np = np.array(obsArray)\n",
    "\n",
    "#             plt.xlabel('Step')\n",
    "#             plt.ylabel('SOC')\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             plt.ylim([-10, 100])\n",
    "\n",
    "\n",
    "#             i = 0\n",
    "#             for soc in data_np.T:\n",
    "#                 plt.plot(np.arange(start=0, stop=len(data_np), step=1), soc.flatten(), label=\"soc\"+str(i))\n",
    "#                 i += 1\n",
    "\n",
    "#             plt.legend()\n",
    "#             #plt.pause(3)\n",
    "\n",
    "#             obsArray = []\n",
    "#             episode_reward = 0\n",
    "#             obs = model.get_env().reset()\n",
    "\n",
    "#             break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_trained_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.monitor import Monitor\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines3 import A2C, SAC, PPO, TD3\n",
    "\n",
    "# env = Monitor(gym.make(\"Pendulum-v1\"))\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# model = A2C(\"MlpPolicy\", env, verbose=1).learn(int(5000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
