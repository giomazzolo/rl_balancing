{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable_baselines3 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (2.2.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stable_baselines3) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable_baselines3) (2024.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from pandas->stable_baselines3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from pandas->stable_baselines3) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
      "^C\n",
      "Requirement already satisfied: ipykernel in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (6.29.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (8.21.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.7.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (5.14.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (306)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\envs\\stable_baselines\\lib\\site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\matei\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "#!pip install stable-baselines3[extra]\n",
    "\n",
    "# -- Prerequisites install \n",
    "!pip3 install stable_baselines3 --user\n",
    "!pip3 install stable_baselines3 --user\n",
    "!pip3 install ipykernel --user\n",
    "!pip3 install tensorboard --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{hidden_layers_policy_network}\n",
      "3     randint\n",
      "4       Literal{4}\n",
      "5   Literal{1}\n",
      "6   Literal{2}\n",
      "7   Literal{3}\n",
      "8   Literal{4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A493191\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\policies.py:484: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x16e38658190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import stable_baselines3\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "\n",
    "#from stable_baselines3 import DQN,PPO,A2C\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "\n",
    "from hyperopt import hp,fmin,tpe\n",
    "import torch as th\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def set_up_model(params, env):\n",
    "    log_path = os.path.join('Training', 'Logs')\n",
    "    hidden_layers_policy_network = params['hidden_layers_policy_network']\n",
    "    size_hidden_layers_policy_network = params['size_hidden_layers_policy_network']\n",
    "    hidden_layers_value_network = params['hidden_layers_value_network']\n",
    "    size_hidden_layers_value_network = params['size_hidden_layers_value_network']\n",
    "\n",
    "    net_arch = [dict(pi=([size_hidden_layers_policy_network] * hidden_layers_policy_network),vf=([size_hidden_layers_value_network] * hidden_layers_value_network))]\n",
    "\n",
    "    activation_fn = {\"tanh\": th.nn.Tanh, \"relu\": th.nn.ReLU, \"elu\": th.nn.ELU, \"leaky_relu\": th.nn.LeakyReLU}[params['activation_fn']]\n",
    "\n",
    "    policy_kwargs = dict(net_arch=net_arch,\n",
    "                    ortho_init=params['ortho_init'],\n",
    "                    activation_fn=activation_fn)\n",
    "\n",
    "    batch_size = math.gcd(params['batch_size'],params['n_steps'])\n",
    "\n",
    "    model = PPO(\"MlpPolicy\",\n",
    "                env, \n",
    "                learning_rate=params['learning_rate'], \n",
    "                n_steps=params['n_steps'], \n",
    "                batch_size=batch_size, \n",
    "                n_epochs=params['n_epochs'], \n",
    "                gamma=params['gamma'], \n",
    "                gae_lambda=params['gae_lambda'], \n",
    "                clip_range=params['clip_range'], \n",
    "                ent_coef=params['ent_coef'], \n",
    "                vf_coef=params['vf_coef'], \n",
    "                max_grad_norm=params['max_grad_norm'],\n",
    "                policy_kwargs=policy_kwargs,\n",
    "                verbose=0, \n",
    "                tensorboard_log=log_path,\n",
    "                device='cuda')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "space = {\n",
    "        'learning_rate': 5e-6,\n",
    "        'n_steps': 128,\n",
    "        'batch_size': 128,\n",
    "        'n_epochs': 10,\n",
    "        'gamma': 0.99,\n",
    "        'gae_lambda': 0.9,\n",
    "        'clip_range': 0.2,\n",
    "        'ent_coef': 0,\n",
    "        'vf_coef': 0.5,\n",
    "        'max_grad_norm': 0.5,\n",
    "        'lr_schedule': 'linear',\n",
    "        'hidden_layers_policy_network': 2,\n",
    "        'size_hidden_layers_policy_network': 128,\n",
    "        'hidden_layers_value_network': 2,\n",
    "        'size_hidden_layers_value_network': 128,\n",
    "        'ortho_init': False,\n",
    "        'activation_fn': \"relu\"\n",
    "    }\n",
    "\n",
    "\n",
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = BatteryEnv()\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "\n",
    "check_env(env, warn=True)\n",
    "\n",
    "print(hp.choice('hidden_layers_policy_network', [1,2,3,4]))\n",
    "\n",
    "model = set_up_model(space,env)\n",
    "\n",
    "model.learn(total_timesteps=1000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STABLEBASELINES TESTBED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery env \n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from typing import Optional, Union\n",
    "\n",
    "#class BatteryEnv(gym.Env[np.ndarray, Union[int, np.ndarray]]):\n",
    "\n",
    "class BatteryEnv(gym.Env):\n",
    "\n",
    "   def __init__(self, nr_batteries, render_mode: Optional[str] = None):\n",
    "      super().__init__()\n",
    "      #self.zk = 9.8  # = SOC\n",
    "      #self.hk = 1.0  # = hysteresis state\n",
    "      #self.t = 1.0   # = temperature\n",
    "      #self.vk = 1.0\n",
    "      #self.rck = 1.0 # = Current through paralel resistor\n",
    "\n",
    "      #     action_high = np.array(\n",
    "      #       [\n",
    "      #       #   10,         #min= 0, max= 10       Voltage (v) - vk\n",
    "      #          80,        #min= 0, max= 100      SOC - zk\n",
    "      #          80,        #min= 0, max= 100      SOC - zk\n",
    "      #       #   150,        #min= -30, max= 150    Temperature  - t\n",
    "      #       #   1,          #min= -1, max= 1       Hysteresis state - hk\n",
    "      #       #   100,        #min= -100, max= 100   Current through paralel resistor - rck\n",
    "      #       #   33459,      # time \n",
    "      #       #   np.finfo(np.float32).max,   #min= Inf, max= Inf\n",
    "      #    ],\n",
    "      #    dtype=np.float64,\n",
    "      # )\n",
    "      \n",
    "      #...\n",
    "\n",
    "      self.env_id = \"Battery v0.3\"\n",
    "      self.num_envs = 1\n",
    "      \n",
    "      # SOHt​=f(SOCt​,CRt​) - soh as function of charge rate and soc\n",
    "      # SOHt​=SOHt−1​−k×CRt​\n",
    "      self.degradation_coeficient = 0.2\n",
    "\n",
    "      self.soc_threshold_upper = 85\n",
    "      self.soc_threshold_lower = 15\n",
    "\n",
    "      self.episode_time = 0\n",
    "\n",
    "      self.nr_batteries = nr_batteries\n",
    "\n",
    "\n",
    "\n",
    "      high = np.array(\n",
    "            [\n",
    "               100,        #min= 0, max= 100      SOC - zk\n",
    "               100,        #min= 0, max= 100      SOC - zk\n",
    "         ],\n",
    "         dtype=np.float32,\n",
    "      )\n",
    "\n",
    "      low = np.array(\n",
    "            [\n",
    "               0,\n",
    "               0,\n",
    "         ],\n",
    "         dtype=np.float32,\n",
    "      )\n",
    "\n",
    "\n",
    "      self.action_space = gym.spaces.Box(-1, 1, (self.nr_batteries,), dtype=np.float32) # cell1,cell2,cell3... and voltage\n",
    "      self.observation_space = gym.spaces.Box(0, 100, (self.nr_batteries,), dtype=np.float32)\n",
    "\n",
    "      self.state = None\n",
    "      self.steps_beyond_terminated = None\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "   def step(self, action):\n",
    "      err_msg = f\"{action!r} ({type(action)}) invalid\"\n",
    "      assert self.action_space.contains(action), err_msg\n",
    "      assert self.state is not None, \"Call reset before using step method.\"\n",
    "\n",
    "\n",
    "      battery_current_values = get_converted_action(action)\n",
    "\n",
    "      #vk, zk, t, hk, rck, time = self.state\n",
    "\n",
    "\n",
    "      # discharge until 15, and 85 limilits\n",
    "      #print(action)\n",
    "\n",
    "\n",
    "      self.episode_time += 1\n",
    "      passed_threshold = False\n",
    "      exiting_observation_space = False\n",
    "\n",
    "      self.state = np.subtract(self.state, battery_current_values)         \n",
    "\n",
    "      for soc in self.state:\n",
    "\n",
    "         if (soc < self.soc_threshold_lower or soc > self.soc_threshold_upper):\n",
    "            passed_threshold = True\n",
    "         if (soc < 0 or soc > 100):\n",
    "            # EXITED OBSERVATION SPACE. Terminate immediatley.\n",
    "            soc = 0.0\n",
    "            exiting_observation_space = True\n",
    "            print(\"//////// EXITED OBSERVATION SPACE BOUNDS ////////  \"  + str(soc))\n",
    "            #return np.array(self.state , dtype=np.float32), -10000000000000, True, False, {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # right now the reward in only based on if the variables fall out of bounds \n",
    "      # passed_thr = bool(\n",
    "      #    soc0 < self.soc_threshold_lower\n",
    "      #    or soc0 > self.soc_threshold_upper\n",
    "      #    or soc1 < self.soc_threshold_lower\n",
    "      #    or soc1 > self.soc_threshold_upper\n",
    "      #    # time doesnt really make sense here for now\n",
    "      #    #or time < 0\n",
    "      #    #or time > 33458\n",
    "      # )\n",
    "\n",
    "\n",
    "      terminated = False\n",
    "\n",
    "      reward = 0\n",
    "      if not passed_threshold and self.episode_time == 128:\n",
    "         # Timeout\n",
    "         self.episode_time = 0\n",
    "         # reward = 0\n",
    "         reward = compute_ballancing_reward(self.state, False)\n",
    "         terminated = True\n",
    "      elif not passed_threshold:\n",
    "         # Apply cost(reward)\n",
    "         # if (math.isclose(soc0, soc1, abs_tol=1)):\n",
    "         #    reward = 0\n",
    "         # else:\n",
    "         reward = compute_ballancing_reward(self.state, False)\n",
    "\n",
    "      \n",
    "      elif passed_threshold:\n",
    "         # Batteries drained! Terminated.\n",
    "         self.steps_beyond_terminated = 0\n",
    "         \n",
    "         #terminated = True\n",
    "         #self.episode_time = 0\n",
    "         reward = -10000\n",
    "\n",
    "         #if self.episode_time == 128:\n",
    "         terminated = True\n",
    "\n",
    "      # Sanity check. Do not continue steps after termination. Call reset first.\n",
    "      # if self.steps_beyond_terminated > 0:\n",
    "      #    print(\n",
    "      #       \"You are calling 'step()' even though this \"\n",
    "      #       \"environment has already returned terminated = True. You \"\n",
    "      #       \"should always call 'reset()' once you receive 'terminated = \"\n",
    "      #       \"True' -- any further steps are undefined behavior.\"\n",
    "      #    )\n",
    "      #    self.steps_beyond_terminated += 1\n",
    "      #    reward = 0.0\n",
    "\n",
    "\n",
    "      if self.render_mode == \"human\":\n",
    "         self.render()\n",
    "      \n",
    "      return np.array(self.state, dtype=np.float32), float(reward), terminated, False, {}\n",
    "   \n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "   def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,):\n",
    "        \n",
    "\n",
    "         super().reset(seed=seed)\n",
    "         # Note that if you use custom reset bounds, it may lead to out-of-bound\n",
    "         # state/observations.\n",
    "         #high = utils.maybe_parse_reset_bounds(\n",
    "         #    options, -0.05, 0.05  # default low\n",
    "         #)  # default high\n",
    "\n",
    "\n",
    "         self.episode_time = 0\n",
    "\n",
    "         #definition of an episode: 1 whole run of the matlab script\n",
    "         #                               OR\n",
    "         #                          1 segment of it?\n",
    "\n",
    "         self.state = self.np_random.uniform(low=15, high=85, size=(self.nr_batteries,))\n",
    "\n",
    "         self.steps_beyond_terminated = None\n",
    "\n",
    "         if self.render_mode == \"human\":\n",
    "               self.render()\n",
    "         return np.array(self.state, dtype=np.float32), {}\n",
    "\n",
    "\n",
    "\n",
    "def compute_ballancing_reward(socs, should_print):\n",
    "\n",
    "   \n",
    "   #cost as distance between 2 numbers\n",
    "   #reward = -pow(soc0 - soc1, 2)\n",
    "   \n",
    "   #cost as standard deviation\n",
    "   reward = -np.std(socs, dtype=np.float32)\n",
    "\n",
    "   # if(should_print):\n",
    "   #    print( \"SOC Mean: \" + str(mean) +  \"    ---- SOC1 Difference    \"  + str(difference1)  +  \"    ----   SOC2 Difference    \"  + str(difference2))\n",
    "\n",
    "   return reward\n",
    "\n",
    "\n",
    "def get_converted_action(action):\n",
    "   current_values = []\n",
    "   for current in action:\n",
    "      shifted_value = (current + 1.0) * 5.0  #from [-1, 1] to [0, 10]\n",
    "      current_values.append(shifted_value)\n",
    "\n",
    "   return current_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def plot_step(episode_number, state, action, reward, show_result=False):\n",
    "    \n",
    "    fig = plt.figure(1)\n",
    "\n",
    "    actions_t = torch.tensor(action, dtype=torch.float)\n",
    "    rewards_t = torch.tensor(reward, dtype=torch.float)\n",
    "\n",
    "    plt.title('Episode ' + str(episode_number))\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('SOC & Actions')\n",
    "\n",
    "\n",
    "\n",
    "    # Plot SOCs\n",
    "    soc0 = []\n",
    "    soc1 = []\n",
    "    for st in state:\n",
    "        # states_t = torch.tensor(st, dtype=torch.float)\n",
    "        # plt.plot(states_t.cpu().squeeze().numpy(), label='State ' + str(st))\n",
    "\n",
    "        soc0.append(st[0][0].item())\n",
    "        soc1.append(st[0][1].item())\n",
    "    \n",
    "    plt.plot(soc0, label='soc0')\n",
    "    plt.plot(soc1, label='soc1')\n",
    "\n",
    "\n",
    "\n",
    "    # Plot actions as indvidual points\n",
    "    action_array = np.multiply(actions_t.numpy(), 10)   # multiply action values by 10 for better display on graph\n",
    "    plt.plot(action_array, 'bo', markersize=0.4, label='Action')\n",
    "    line_nr = 0\n",
    "\n",
    "    # Plot action value as text above point\n",
    "    # for line in action_array:\n",
    "    #     plt.text(line_nr, line+1.8, str(int(line)), horizontalalignment='center', size='small', color='black')\n",
    "    #     line_nr = line_nr + 1 \n",
    "\n",
    "\n",
    "    # Plot actions as single point average\n",
    "    # Take 100 steps average and plot the average action for that period\n",
    "    # if len(actions_t) >= 10:\n",
    "    #     means = actions_t.unfold(0, 10, 1).mean(1).view(-1)\n",
    "    #     means = torch.cat((torch.zeros(9), means))\n",
    "    #     plt.plot(means.numpy(), 'go', markersize=1, label='Action')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    # Plot rewards\n",
    "    # Reduces displayed rewards by an order of 10 to fit within the graph\n",
    "    fig2 = plt.figure(2)\n",
    "    plt.title('Episode ' + str(episode_number))\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Reward')\n",
    "    #plt.plot(np.divide(rewards_t.numpy(), 10), label='Reward')\n",
    "    plt.plot(rewards_t.numpy(), label='Reward')\n",
    "\n",
    "    # add legend with labels\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.pause(0.0001)  # pause a bit so that plots are updated\n",
    "    #if is_ipython:\n",
    "    if not show_result:\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    else:\n",
    "        display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\A493191\\AppData\\Local\\anaconda3\\envs\\stable_baselines\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "\n",
    "#from stable_baselines3 import DQN,PPO,A2C\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "\n",
    "from hyperopt import hp,fmin,tpe\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "\n",
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            # print(x[-100:])\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"SAVE CALLBACK: Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"SAVE CALLBACK Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "                    #print (self.training_env.state)\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"SAVE CALLBACK: Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gymnasium[box2d]\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "from stable_baselines3.common.vec_env.vec_monitor import VecMonitor\n",
    "\n",
    "\n",
    "\n",
    "# Create log dir\n",
    "log_dir = \"./tmp/gym/ppotest/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = BatteryEnv(5, False)\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# env = VecNormalize(env, norm_reward=True, norm_obs=False)\n",
    "env = VecMonitor(env, log_dir) #monitor for vec environments\n",
    "\n",
    "#env = Monitor(env, log_dir) #monitor for raw environments\n",
    "\n",
    "\n",
    "\n",
    "# run random env tests tomake sure everything is in order\n",
    "# for i in range(0, 100):\n",
    "#     check_env(env)\n",
    "\n",
    "\n",
    "#env = gym.wrappers.RecordEpisodeStatistics(env, 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C, SAC, PPO, TD3\n",
    "\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy, BasePolicy, MultiInputActorCriticPolicy\n",
    "\n",
    "\n",
    "print(\"Is CUDA enabled?\", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Create action noise because TD3 and DDPG use a deterministic policy\n",
    "#n_actions = env.action_space.shape[-1]\n",
    "#action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# Create the callback: check every 1000 steps\n",
    "#callback = SaveOnBestTrainingRewardCallback(check_freq=512, log_dir=log_dir)\n",
    "\n",
    "# Create RL model\n",
    "#model = PPO('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./ppo_tensorboard_log/\", learning_rate=1e-4, gamma=0.20)\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    'learning_rate': 0.0003,  # Learning rate\n",
    "    'n_steps': 2048,  # Number of steps per epoch\n",
    "    'batch_size': 256,  # Minibatch size for SGD\n",
    "    'ent_coef': 0.01,  # Entropy coefficient for exploration\n",
    "    # 'gamma': 0.99,  # Discount factor\n",
    "    'gae_lambda': 0.95,  # Lambda coefficient (controls bias-variance trade-off in advantage estimation)\n",
    "    'clip_range': 0.2,  # Clip range for PPO clip loss\n",
    "    'n_epochs': 4,  # Number of epochs per update\n",
    "    'max_grad_norm': 0.5,  # Max norm of gradients\n",
    "    'vf_coef': 0.5,  # Value function coefficient in the total loss\n",
    "    # 'use_sde': False,  # Whether to use Squashed Diagonal Gaussian policy\n",
    "    # 'sde_sample_freq': -1,  # Sample frequency for SDE when `use_sde=True`\n",
    "}\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./ppo_tensorboard_log/\", policy_kwargs={'net_arch':dict(pi=[256, 256, 256],\n",
    "                                                                                                                                 vf=[256, 256, 256])}, **hyperparameters)\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./ppo_tensorboard_log/\")\n",
    "\n",
    "\n",
    "#callback = EvalCallback(env, log_path=log_dir, n_eval_episodes= 20, eval_freq= 20*128, callback_after_eval=SaveOnBestTrainingRewardCallback(check_freq=1, log_dir=log_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-10390.62 +/- 175.81\n",
      "Episode length: 63.40 +/- 30.96\n",
      "New best mean reward!\n",
      "Eval num_timesteps=20000, episode_reward=-10262.74 +/- 156.27\n",
      "Episode length: 41.60 +/- 21.62\n",
      "New best mean reward!\n",
      "Eval num_timesteps=30000, episode_reward=-10285.48 +/- 186.71\n",
      "Episode length: 38.60 +/- 22.04\n",
      "Eval num_timesteps=40000, episode_reward=-10232.03 +/- 141.29\n",
      "Episode length: 29.40 +/- 17.34\n",
      "New best mean reward!\n",
      "Eval num_timesteps=50000, episode_reward=-10195.35 +/- 71.61\n",
      "Episode length: 46.00 +/- 22.73\n",
      "New best mean reward!\n",
      "Eval num_timesteps=60000, episode_reward=-10174.46 +/- 87.41\n",
      "Episode length: 35.20 +/- 33.89\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70000, episode_reward=-10110.69 +/- 52.34\n",
      "Episode length: 13.20 +/- 7.73\n",
      "New best mean reward!\n",
      "Eval num_timesteps=80000, episode_reward=-10247.29 +/- 128.12\n",
      "Episode length: 40.60 +/- 27.64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m modelSAC \u001b[38;5;241m=\u001b[39m SAC(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saccombo_tensorboard_log/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m eval_cb \u001b[38;5;241m=\u001b[39m EvalCallback(env, log_path\u001b[38;5;241m=\u001b[39mlog_dir, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 25\u001b[0m modelSAC\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m100000\u001b[39m), callback\u001b[38;5;241m=\u001b[39meval_cb)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#------------ TD3\u001b[39;00m\n\u001b[0;32m     31\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./tmp/gym/td3combo/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[0;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    308\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    309\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    310\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    311\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    312\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    313\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    314\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, gradient_steps\u001b[38;5;241m=\u001b[39mgradient_steps)\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\sac\\sac.py:280\u001b[0m, in \u001b[0;36mSAC.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Optimize the actor\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 280\u001b[0m actor_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# Update target networks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3 import A2C, SAC, PPO, TD3\n",
    "\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy, BasePolicy, MultiInputActorCriticPolicy\n",
    "\n",
    "\n",
    "\n",
    "#------------ SAC\n",
    "\n",
    "\n",
    "log_dir = \"./tmp/gym/saccombo/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = BatteryEnv(5, False)\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# env = VecNormalize(env, norm_reward=True, norm_obs=False)\n",
    "env = VecMonitor(env, log_dir) #monitor for vec environments\n",
    "\n",
    "# Train the agent\n",
    "modelSAC = SAC('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./saccombo_tensorboard_log/\")\n",
    "\n",
    "eval_cb = EvalCallback(env, log_path=log_dir, verbose=True)\n",
    "modelSAC.learn(total_timesteps=int(100000), callback=eval_cb)\n",
    "\n",
    "\n",
    "#------------ TD3\n",
    "\n",
    "\n",
    "log_dir = \"./tmp/gym/td3combo/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = BatteryEnv(5, False)\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# env = VecNormalize(env, norm_reward=True, norm_obs=False)\n",
    "env = VecMonitor(env, log_dir) #monitor for vec environments\n",
    "\n",
    "# Train the agent\n",
    "modelTD3 = TD3('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./td3combo_tensorboard_log/\")\n",
    "\n",
    "eval_cb = EvalCallback(env, log_path=log_dir)\n",
    "modelTD3.learn(total_timesteps=int(1000000), callback=eval_cb)\n",
    "\n",
    "#------------ A2C\n",
    "\n",
    "\n",
    "log_dir = \"./tmp/gym/a2ccombo/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = BatteryEnv(5, False)\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# env = VecNormalize(env, norm_reward=True, norm_obs=False)\n",
    "env = VecMonitor(env, log_dir) #monitor for vec environments\n",
    "\n",
    "# Train the agent\n",
    "modelA2C = A2C('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./a2ccombo_tensorboard_log/\")\n",
    "\n",
    "eval_cb = EvalCallback(env, log_path=log_dir)\n",
    "modelA2C.learn(total_timesteps=int(1000000), callback=eval_cb)\n",
    "\n",
    "\n",
    "\n",
    "#------------ PPO\n",
    "\n",
    "log_dir = \"./tmp/gym/ppocombo/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = BatteryEnv(5, False)\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# env = VecNormalize(env, norm_reward=True, norm_obs=False)\n",
    "env = VecMonitor(env, log_dir) #monitor for vec environments\n",
    "\n",
    "# Train the agent\n",
    "modelPPO = PPO('MlpPolicy', env, verbose=0, device=\"cuda\", tensorboard_log=\"./ppocombo_tensorboard_log/\")\n",
    "\n",
    "eval_cb = EvalCallback(env, log_path=log_dir)\n",
    "modelPPO.learn(total_timesteps=int(1000000000), callback=eval_cb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results(\n",
    "    [log_dir], 1e6, results_plotter.X_TIMESTEPS, \"PPO - Env: Battery\"\n",
    ")\n",
    "\n",
    "\n",
    "# reduce samples: callback: eval callback episodes and eval_freq\n",
    "#                 env: n_steps, n_epochs, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5986, episode_reward=-10198.35 +/- 39.67\n",
      "Episode length: 47.00 +/- 14.52\n",
      "Eval num_timesteps=15986, episode_reward=-10243.41 +/- 148.78\n",
      "Episode length: 47.20 +/- 30.68\n",
      "Eval num_timesteps=25986, episode_reward=-10271.14 +/- 135.29\n",
      "Episode length: 52.40 +/- 33.77\n",
      "Eval num_timesteps=35986, episode_reward=-10309.70 +/- 97.46\n",
      "Episode length: 55.60 +/- 20.13\n",
      "Eval num_timesteps=45986, episode_reward=-10288.20 +/- 147.76\n",
      "Episode length: 43.40 +/- 32.50\n",
      "Eval num_timesteps=55986, episode_reward=-10270.81 +/- 119.73\n",
      "Episode length: 60.60 +/- 23.34\n",
      "Eval num_timesteps=65986, episode_reward=-10272.80 +/- 88.33\n",
      "Episode length: 62.00 +/- 28.79\n",
      "Eval num_timesteps=75986, episode_reward=-10141.33 +/- 66.78\n",
      "Episode length: 36.60 +/- 31.54\n",
      "Eval num_timesteps=85986, episode_reward=-10333.04 +/- 163.13\n",
      "Episode length: 52.40 +/- 28.70\n",
      "Eval num_timesteps=95986, episode_reward=-10378.02 +/- 208.07\n",
      "Episode length: 55.80 +/- 21.67\n",
      "Eval num_timesteps=105986, episode_reward=-10244.13 +/- 188.96\n",
      "Episode length: 49.60 +/- 40.15\n",
      "Eval num_timesteps=115986, episode_reward=-10217.29 +/- 64.57\n",
      "Episode length: 50.80 +/- 16.92\n",
      "Eval num_timesteps=125986, episode_reward=-10257.56 +/- 96.47\n",
      "Episode length: 50.40 +/- 28.34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m modelSAC\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1000000\u001b[39m), callback\u001b[38;5;241m=\u001b[39meval_cb)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[0;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    308\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    309\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    310\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    311\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    312\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    313\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    314\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, gradient_steps\u001b[38;5;241m=\u001b[39mgradient_steps)\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\sac\\sac.py:280\u001b[0m, in \u001b[0;36mSAC.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Optimize the actor\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 280\u001b[0m actor_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# Update target networks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelSAC.learn(total_timesteps=int(1000000), callback=eval_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3.common import results_plotter\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results(\n",
    "    [log_dir], 1e7, results_plotter.X_TIMESTEPS, \"PPO - Env: Battery\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def moving_average(values, window):\n",
    "    \"\"\"\n",
    "    Smooth values by doing a moving average\n",
    "    :param values: (numpy array)\n",
    "    :param window: (int)\n",
    "    :return: (numpy array)\n",
    "    \"\"\"\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, \"valid\")\n",
    "\n",
    "\n",
    "def plot_results(log_folder, title=\"Learning Curve\"):\n",
    "    \"\"\"\n",
    "    plot the results\n",
    "\n",
    "    :param log_folder: (str) the save location of the results to plot\n",
    "    :param title: (str) the title of the task to plot\n",
    "    \"\"\"\n",
    "    x, y = ts2xy(load_results(log_folder), \"timesteps\")\n",
    "    y = moving_average(y, window=50)\n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y) :]\n",
    "\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"Number of Timesteps\")\n",
    "    plt.ylabel(\"Rewards\")\n",
    "    plt.title(title + \" Smoothed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_results(log_dir)\n",
    "\n",
    "\n",
    "# study value and policy more\n",
    "# view episides during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelA2C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 116\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# def test_paralel_model():\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#     env = BatteryEnv(5, False)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m#             break\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m test_trained_model()\n",
      "Cell \u001b[1;32mIn[48], line 6\u001b[0m, in \u001b[0;36mtest_trained_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_trained_model\u001b[39m():\n\u001b[1;32m----> 6\u001b[0m     model\u001b[38;5;241m=\u001b[39m modelA2C\n\u001b[0;32m      7\u001b[0m     obs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_env()\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      8\u001b[0m     episode_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelA2C' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def test_trained_model():\n",
    "    model= modelPPO\n",
    "    obs = model.get_env().reset()\n",
    "    episode_reward = 0\n",
    "\n",
    "    obsArray = []\n",
    "\n",
    "    while True:\n",
    "        obsArray.append(obs)\n",
    "        action, _states = model.predict(obs)\n",
    "        oldObs = obs\n",
    "        obs, rewards, done, info = model.get_env().step(action)\n",
    "        episode_reward += rewards.squeeze()\n",
    "\n",
    "        if not done:\n",
    "            print(str(oldObs) + \"  ACTION:\" + str(get_converted_action(action)[0]) + \"  >>>> \")\n",
    "            print(str(obs) + \"  REWARD:  \"  + str(rewards) + \"   \")\n",
    "        else:\n",
    "            info_item = info.pop()\n",
    "            print(\"FINAL: \")\n",
    "            print(str(info_item.get('terminal_observation'))  + \"       ACTION:\" )\n",
    "            print(str(str(get_converted_action(action.flatten()))))\n",
    "            print(\"REWARD:  \" + str(rewards[0]))\n",
    "            print(\"EPISODE TOTAL REWARD: \" + str(episode_reward))\n",
    "\n",
    "            # plot final model\n",
    "            fig = plt.figure(1)\n",
    "\n",
    "            data_np = np.array(obsArray)\n",
    "\n",
    "            plt.xlabel('Step')\n",
    "            plt.ylabel('SOC')\n",
    "            print(\"------------------------------------------------------\")\n",
    "            plt.ylim([-10, 100])\n",
    "\n",
    "\n",
    "            i = 0\n",
    "            for soc in data_np.T:\n",
    "                plt.plot(np.arange(start=0, stop=len(data_np), step=1), soc.flatten(), label=\"soc\"+str(i))\n",
    "                i += 1\n",
    "\n",
    "            plt.legend()\n",
    "            #plt.pause(3)\n",
    "\n",
    "            obsArray = []\n",
    "            episode_reward = 0\n",
    "            obs = model.get_env().reset()\n",
    "\n",
    "            #time.sleep(0.5)\n",
    "            break\n",
    "\n",
    "\n",
    "# def test_paralel_model():\n",
    "\n",
    "#     env = BatteryEnv(5, False)\n",
    "#     env = DummyVecEnv([lambda: env])\n",
    "\n",
    "#     # intialized here\n",
    "#     obs = env.reset()\n",
    "    \n",
    "#     episode_reward = 0\n",
    "#     obsArray = []\n",
    "\n",
    "#     while True:\n",
    "#         action, _states = model.predict(obs)\n",
    "#         oldObs = obs\n",
    "#         obs, rewards, done, info = model.get_env().step(action)\n",
    "#         episode_reward += rewards.squeeze()\n",
    "\n",
    "#         print(str(oldObs) + \"  ACTION:\" + str(action) + \"  >>>> \")\n",
    "\n",
    "\n",
    "#         if not done:\n",
    "#             print(str(oldObs) + \"  ACTION:\" + str(action) + \"  >>>> \")\n",
    "#             print(str(obs) + \"  REWARD:  \"  + str(rewards) + \"   \")\n",
    "#         else:\n",
    "#             info_item = info.pop()\n",
    "#             print(\"FINAL: \")\n",
    "#             print(str(info_item.get('terminal_observation'))  + \"       ACTION:\" )\n",
    "#             print(str(str(action.flatten())))\n",
    "#             print(\"REWARD:  \" + str(rewards[0]))\n",
    "#             print(\"EPISODE TOTAL REWARD: \" + str(episode_reward))\n",
    "\n",
    "#             # plot final model\n",
    "#             fig = plt.figure(1)\n",
    "\n",
    "#             data_np = np.array(obsArray)\n",
    "\n",
    "#             plt.xlabel('Step')\n",
    "#             plt.ylabel('SOC')\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             plt.ylim([-10, 100])\n",
    "\n",
    "\n",
    "#             i = 0\n",
    "#             for soc in data_np.T:\n",
    "#                 plt.plot(np.arange(start=0, stop=len(data_np), step=1), soc.flatten(), label=\"soc\"+str(i))\n",
    "#                 i += 1\n",
    "\n",
    "#             plt.legend()\n",
    "#             #plt.pause(3)\n",
    "\n",
    "#             obsArray = []\n",
    "#             episode_reward = 0\n",
    "#             obs = model.get_env().reset()\n",
    "\n",
    "#             break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_trained_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.monitor import Monitor\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines3 import A2C, SAC, PPO, TD3\n",
    "\n",
    "# env = Monitor(gym.make(\"Pendulum-v1\"))\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# model = A2C(\"MlpPolicy\", env, verbose=1).learn(int(5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIPEDAL WALKER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'BipedalWalker-v3'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 390      |\n",
      "|    ep_rew_mean     | -114     |\n",
      "| time/              |          |\n",
      "|    fps             | 659      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 419         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009753135 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | -0.00667    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008443112 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | -0.0338     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 626         |\n",
      "|    ep_rew_mean          | -119        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009590036 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | -0.751      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 0.654       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 696         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006473873 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 756         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013206612 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 0.698       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 809         |\n",
      "|    ep_rew_mean          | -116        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015069576 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.51       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 897          |\n",
      "|    ep_rew_mean          | -113         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111146625 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.47        |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.03         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.017       |\n",
      "|    std                  | 0.948        |\n",
      "|    value_loss           | 0.13         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 892         |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009495972 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0891      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 926         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009740333 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0599      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 956         |\n",
      "|    ep_rew_mean          | -108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011121174 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -105         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120747825 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.34        |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.028        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    std                  | 0.914        |\n",
      "|    value_loss           | 0.121        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010634444 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.909       |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -102        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009890558 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.25       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0525      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 0.89        |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -98.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010391884 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0702      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    std                  | 0.88        |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -96.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008279025 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0703      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -94         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014065317 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.08       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0458      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -91.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015372056 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0878      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -86         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009580353 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0738      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -83.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010806337 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0977      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -80.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010461904 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.098       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -74.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012146966 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.84       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.807       |\n",
      "|    value_loss           | 0.407       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -72.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012385653 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.794       |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -68.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 511          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065602064 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75        |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.793        |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.22e+03  |\n",
      "|    ep_rew_mean          | -65.4     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 512       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0114161 |\n",
      "|    clip_fraction        | 0.147     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.74     |\n",
      "|    explained_variance   | 0.826     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.277     |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -0.0143   |\n",
      "|    std                  | 0.789     |\n",
      "|    value_loss           | 0.604     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -58.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009909635 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.784       |\n",
      "|    value_loss           | 0.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -59.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009879134 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.78        |\n",
      "|    value_loss           | 0.426       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -51.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009138757 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 0.777       |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -51.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011001296 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    std                  | 0.765       |\n",
      "|    value_loss           | 0.353       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -48.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 514          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065977876 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.6         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    std                  | 0.762        |\n",
      "|    value_loss           | 44.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -45.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 514          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093612205 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.58        |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 0.758        |\n",
      "|    value_loss           | 0.273        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -46.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006132998 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    std                  | 0.759       |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.18e+03   |\n",
      "|    ep_rew_mean          | -42.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837772 |\n",
      "|    clip_fraction        | 0.0669     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.57      |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.7       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00843   |\n",
      "|    std                  | 0.759      |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -37.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009236629 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0785      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -34.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742219 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    std                  | 0.751       |\n",
      "|    value_loss           | 9.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -35.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010865871 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    std                  | 0.743       |\n",
      "|    value_loss           | 0.388       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.16e+03     |\n",
      "|    ep_rew_mean          | -30.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056610974 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.49        |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    std                  | 0.743        |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -28.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014452688 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.73        |\n",
      "|    value_loss           | 0.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -25.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012042879 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.72        |\n",
      "|    value_loss           | 0.455       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -22.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008472552 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.37       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    std                  | 0.723       |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -26.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009720733 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.37       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.651       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    std                  | 0.721       |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -24.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049350024 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.37        |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    std                  | 0.72         |\n",
      "|    value_loss           | 86.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -21.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010852566 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.36       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4           |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.721       |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -19.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012401659 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.37       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.678       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 0.721       |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -17         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012415215 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.34       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.348       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    std                  | 0.713       |\n",
      "|    value_loss           | 0.746       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -15         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011571474 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.96        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    std                  | 0.713       |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.13e+03   |\n",
      "|    ep_rew_mean          | -13.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 512        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01958611 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.3       |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.207      |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 0.706      |\n",
      "|    value_loss           | 0.585      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -9.56       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011431331 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -10.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009993846 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.205       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 0.536       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.13e+03     |\n",
      "|    ep_rew_mean          | -8.94        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073067765 |\n",
      "|    clip_fraction        | 0.0964       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.24        |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.29         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    std                  | 0.699        |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -7.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015719114 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 0.752       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -4.76       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011610868 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0856      |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.686       |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -3.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011637051 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.383       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    std                  | 0.685       |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -2.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011931774 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.233       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    std                  | 0.677       |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -3.47       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006643218 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.39        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    std                  | 0.678       |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -1.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007114522 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    std                  | 0.679       |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -0.0306      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075129056 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.13        |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    std                  | 0.68         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | 2.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008159103 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    std                  | 0.68        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | 4.79        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006955833 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    std                  | 0.68        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | 6.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009225111 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    std                  | 0.679       |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | 9.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015221011 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    std                  | 0.681       |\n",
      "|    value_loss           | 9.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | 15.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308605 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    std                  | 0.681       |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | 16.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011919649 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    std                  | 0.682       |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | 19.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012553964 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.68        |\n",
      "|    value_loss           | 5.6         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.12e+03   |\n",
      "|    ep_rew_mean          | 22.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 260        |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01286087 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.15      |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.5       |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    std                  | 0.685      |\n",
      "|    value_loss           | 8.61       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 26.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013434208 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.207       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    std                  | 0.676       |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 29.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012084225 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.821       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.676       |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 31.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013589195 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    std                  | 0.677       |\n",
      "|    value_loss           | 8.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 34          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015274974 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | -0.912      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    std                  | 0.667       |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.1e+03   |\n",
      "|    ep_rew_mean          | 36.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 509       |\n",
      "|    iterations           | 70        |\n",
      "|    time_elapsed         | 281       |\n",
      "|    total_timesteps      | 143360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0141901 |\n",
      "|    clip_fraction        | 0.163     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.04     |\n",
      "|    explained_variance   | 0.808     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.258     |\n",
      "|    n_updates            | 690       |\n",
      "|    policy_gradient_loss | -0.0109   |\n",
      "|    std                  | 0.663     |\n",
      "|    value_loss           | 0.576     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 38.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015567938 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0565      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    std                  | 0.65        |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 38.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009116483 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    std                  | 0.651       |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 39.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009007707 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    std                  | 0.651       |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 39.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008363426 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.09        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    std                  | 0.65        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | 37.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 302          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103845615 |\n",
      "|    clip_fraction        | 0.0821       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.95        |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 0.651        |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 39.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009377771 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    std                  | 0.651       |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 42.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011689592 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.292       |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    std                  | 0.654       |\n",
      "|    value_loss           | 0.841       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 43.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013270017 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    std                  | 0.645       |\n",
      "|    value_loss           | 0.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 46.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012365842 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.649       |\n",
      "|    value_loss           | 0.327       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 45.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009595812 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.665       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    std                  | 0.646       |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 45.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 327          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070615364 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    std                  | 0.644        |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 46.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 331         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009338308 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    std                  | 0.643       |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 44.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008365909 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    std                  | 0.639       |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 45          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007269188 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    std                  | 0.64        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 45.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009317717 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.68        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.636       |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 47.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014672198 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.452       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    std                  | 0.63        |\n",
      "|    value_loss           | 0.946       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 50.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016392095 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    std                  | 0.625       |\n",
      "|    value_loss           | 0.349       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012837788 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0879      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    std                  | 0.618       |\n",
      "|    value_loss           | 0.334       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 50.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015867634 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    std                  | 0.611       |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 53.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009991886 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 0.612       |\n",
      "|    value_loss           | 6.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 55.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012861207 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0789      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    std                  | 0.604       |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012504715 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    std                  | 0.594       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 60.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014153482 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.586       |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 63          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009196196 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.577       |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    std                  | 0.586       |\n",
      "|    value_loss           | 5.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 62.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012120023 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0995      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    std                  | 0.581       |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | 63.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 390          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035807807 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.49        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    std                  | 0.581        |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 62.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007636874 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.51        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    std                  | 0.581       |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.09e+03   |\n",
      "|    ep_rew_mean          | 63.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 399        |\n",
      "|    total_timesteps      | 200704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00886035 |\n",
      "|    clip_fraction        | 0.0774     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.48      |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.00728   |\n",
      "|    std                  | 0.58       |\n",
      "|    value_loss           | 15         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 63.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013499526 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    std                  | 0.574       |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 65.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016825086 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.573       |\n",
      "|    value_loss           | 0.408       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 66.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008708186 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.678       |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    std                  | 0.573       |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 67          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012280794 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    std                  | 0.567       |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 69.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011570882 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    std                  | 0.569       |\n",
      "|    value_loss           | 7.65        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | 70.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 502          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 423          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089292545 |\n",
      "|    clip_fraction        | 0.0921       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.88         |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    std                  | 0.566        |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 70.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012550055 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | -0.458      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    std                  | 0.567       |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 70.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017708402 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 0.733       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 73.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015205832 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    std                  | 0.565       |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 73.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015108017 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.56        |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | 76.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013824409 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0643      |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.555       |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | 81.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014386794 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0555      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.547       |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 83.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014770908 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0505      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.541       |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 87.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 456         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015986633 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0458      |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.539       |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | 90.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 502          |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 460          |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070252027 |\n",
      "|    clip_fraction        | 0.0703       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.17        |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    std                  | 0.54         |\n",
      "|    value_loss           | 9.85         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | 96.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 464        |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00945756 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.17      |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.301      |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.00746   |\n",
      "|    std                  | 0.537      |\n",
      "|    value_loss           | 0.626      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 94.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011470377 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.271       |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    std                  | 0.536       |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 97.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009533328 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.905       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    std                  | 0.534       |\n",
      "|    value_loss           | 8.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007158923 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 0.534       |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014245219 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    std                  | 0.534       |\n",
      "|    value_loss           | 0.565       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012594753 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    std                  | 0.529       |\n",
      "|    value_loss           | 0.267       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012748743 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0618      |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.525       |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014022948 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0331      |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.518       |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 495         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011953995 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010911765 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    std                  | 0.513       |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014392461 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.509       |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010476923 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0873      |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 0.507       |\n",
      "|    value_loss           | 2.99        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22e+03   |\n",
      "|    ep_rew_mean          | 112        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 511        |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01743466 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.87      |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0682     |\n",
      "|    n_updates            | 1250       |\n",
      "|    policy_gradient_loss | -0.00947   |\n",
      "|    std                  | 0.495      |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 118         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009101294 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    std                  | 0.495       |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011725637 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.662      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.369       |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.494       |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009329522 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.51        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    std                  | 0.493       |\n",
      "|    value_loss           | 9.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006442882 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    std                  | 0.493       |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22e+03   |\n",
      "|    ep_rew_mean          | 113        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 530        |\n",
      "|    total_timesteps      | 268288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00787138 |\n",
      "|    clip_fraction        | 0.0902     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.09       |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    std                  | 0.493      |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 115         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017225152 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    std                  | 0.497       |\n",
      "|    value_loss           | 0.526       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 118         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019284824 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.075       |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    std                  | 0.498       |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 124         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015181975 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.498       |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.26e+03   |\n",
      "|    ep_rew_mean          | 124        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 546        |\n",
      "|    total_timesteps      | 276480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01981202 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 0.491      |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | 126          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 550          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110304365 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.00733     |\n",
      "|    std                  | 0.491        |\n",
      "|    value_loss           | 10.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 555         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016262636 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0601      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    std                  | 0.487       |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 130         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014556427 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0795      |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.484       |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.28e+03   |\n",
      "|    ep_rew_mean          | 128        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 563        |\n",
      "|    total_timesteps      | 284672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00956157 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.73      |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.461      |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.00471   |\n",
      "|    std                  | 0.485      |\n",
      "|    value_loss           | 6.09       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011647041 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.33        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    std                  | 0.483       |\n",
      "|    value_loss           | 6.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | 129         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018496398 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0816      |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.478       |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | 133         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014286709 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0818      |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 0.472       |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 136         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 580         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015103175 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0368      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.466       |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 136         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016896581 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0829      |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    std                  | 0.462       |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 137         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017566344 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00533     |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.459       |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.3e+03    |\n",
      "|    ep_rew_mean          | 138        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 593        |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01355218 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.5       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0557     |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.00951   |\n",
      "|    std                  | 0.456      |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 142         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 597         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013250827 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    std                  | 0.457       |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x23156225710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C, SAC, PPO, TD3\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "env.reset()\n",
    "\n",
    "model = PPO('MlpPolicy', 'BipedalWalker-v3', verbose=1)\n",
    "\n",
    "TIMESTEPS = 10000\n",
    "\n",
    "model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=\"PPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.19e+03 |\n",
      "|    ep_rew_mean     | 183      |\n",
      "| time/              |          |\n",
      "|    fps             | 676      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 824066   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 185         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 826114      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022337046 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 189         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 828162      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025321743 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.378      |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.92        |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.269       |\n",
      "|    value_loss           | 3.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 192         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 830210      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033699017 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.361      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 1.94        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | 196        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 539        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 832258     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02327914 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02       |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | -0.00793   |\n",
      "|    std                  | 0.269      |\n",
      "|    value_loss           | 2.98       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 196         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 834306      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027286034 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.383      |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.271       |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 199         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 836354      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026160553 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.328       |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.271       |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.26e+03   |\n",
      "|    ep_rew_mean          | 203        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 838402     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02697931 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.383     |\n",
      "|    explained_variance   | 0.628      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 0.27       |\n",
      "|    value_loss           | 1.39       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 204         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 840450      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012123727 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.75        |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 202         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 842498      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023412142 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.344       |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    std                  | 0.269       |\n",
      "|    value_loss           | 6.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 199         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 844546      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017869804 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.373      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73        |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 9.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 194         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 846594      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011312492 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.374      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | 194        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 525        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 848642     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01907122 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.37      |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.6       |\n",
      "|    n_updates            | 4130       |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 0.269      |\n",
      "|    value_loss           | 27.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | 193        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 525        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 850690     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02084333 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.345     |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.982      |\n",
      "|    n_updates            | 4140       |\n",
      "|    policy_gradient_loss | -0.00709   |\n",
      "|    std                  | 0.267      |\n",
      "|    value_loss           | 4.78       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 191         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 852738      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019229818 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01        |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.22e+03  |\n",
      "|    ep_rew_mean          | 190       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 524       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 854786    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0375344 |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.331    |\n",
      "|    explained_variance   | 0.948     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.461     |\n",
      "|    n_updates            | 4160      |\n",
      "|    policy_gradient_loss | -0.00328  |\n",
      "|    std                  | 0.267     |\n",
      "|    value_loss           | 5.46      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22e+03   |\n",
      "|    ep_rew_mean          | 190        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 523        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 856834     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03237601 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.329     |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.426      |\n",
      "|    n_updates            | 4170       |\n",
      "|    policy_gradient_loss | -0.0094    |\n",
      "|    std                  | 0.266      |\n",
      "|    value_loss           | 5.04       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 858882      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042188875 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79        |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.23e+03  |\n",
      "|    ep_rew_mean          | 193       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 522       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 860930    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0431118 |\n",
      "|    clip_fraction        | 0.395     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.311    |\n",
      "|    explained_variance   | 0.512     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.127     |\n",
      "|    n_updates            | 4190      |\n",
      "|    policy_gradient_loss | -0.0124   |\n",
      "|    std                  | 0.265     |\n",
      "|    value_loss           | 1.35      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 190         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 862978      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033355333 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.567       |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    std                  | 0.262       |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 192         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 865026      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023938537 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    std                  | 0.263       |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.24e+03   |\n",
      "|    ep_rew_mean          | 195        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 521        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 867074     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02318158 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.278     |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.37       |\n",
      "|    n_updates            | 4220       |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 0.263      |\n",
      "|    value_loss           | 3.55       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.25e+03   |\n",
      "|    ep_rew_mean          | 198        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 522        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 90         |\n",
      "|    total_timesteps      | 869122     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03811253 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.288     |\n",
      "|    explained_variance   | 0.508      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3          |\n",
      "|    n_updates            | 4230       |\n",
      "|    policy_gradient_loss | -0.00905   |\n",
      "|    std                  | 0.265      |\n",
      "|    value_loss           | 1.63       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 202         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 871170      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023064695 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    std                  | 0.267       |\n",
      "|    value_loss           | 1.75        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.27e+03   |\n",
      "|    ep_rew_mean          | 205        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 523        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 873218     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03793199 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.769      |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | -0.00329   |\n",
      "|    std                  | 0.268      |\n",
      "|    value_loss           | 2.3        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | 208         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 875266      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028589526 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.265       |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.28e+03   |\n",
      "|    ep_rew_mean          | 208        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 523        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 877314     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02826146 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.281     |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.257      |\n",
      "|    n_updates            | 4270       |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    std                  | 0.263      |\n",
      "|    value_loss           | 1.34       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 211         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 879362      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023047872 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.261       |\n",
      "|    value_loss           | 1.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | 211         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 881410      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021326004 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.265       |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.31e+03   |\n",
      "|    ep_rew_mean          | 214        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 523        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 883458     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02246361 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.221     |\n",
      "|    explained_variance   | 0.536      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.398      |\n",
      "|    n_updates            | 4300       |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 0.26       |\n",
      "|    value_loss           | 3.11       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 214         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 885506      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030880256 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.228      |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.293       |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    std                  | 0.261       |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 214         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 887554      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023451364 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.258       |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 214         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 889602      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023621187 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0629      |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.31e+03  |\n",
      "|    ep_rew_mean          | 214       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 524       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 132       |\n",
      "|    total_timesteps      | 891650    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0297181 |\n",
      "|    clip_fraction        | 0.294     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.207    |\n",
      "|    explained_variance   | 0.592     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.31      |\n",
      "|    n_updates            | 4340      |\n",
      "|    policy_gradient_loss | -0.0125   |\n",
      "|    std                  | 0.259     |\n",
      "|    value_loss           | 2.24      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 214         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 893698      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028663203 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.187      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0939      |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 216         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 895746      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025566403 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.193      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 1.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 216         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 897794      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023933046 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.185      |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.858       |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 899842      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022920448 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.171      |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.01        |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 901890      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026086252 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.19       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    std                  | 0.258       |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 903938      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020510094 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.197      |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.258       |\n",
      "|    value_loss           | 4.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 905986      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028960712 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 908034      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026777264 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.628       |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | 222         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 910082      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027581124 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.391       |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 221         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 912130      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023038333 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.208      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.258       |\n",
      "|    value_loss           | 4.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 914178      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011330425 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.196      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.95        |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.258       |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39mTIMESTEPS, reset_num_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tb_log_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[0;32m    316\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[0;32m    317\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    318\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[0;32m    319\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[0;32m    320\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[0;32m    321\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:299\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime/total_timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdump(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps)\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    301\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\ppo\\ppo.py:217\u001b[0m, in \u001b[0;36mPPO.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mreset_noise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m--> 217\u001b[0m values, log_prob, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mevaluate_actions(rollout_data\u001b[38;5;241m.\u001b[39mobservations, actions)\n\u001b[0;32m    218\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\policies.py:730\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    728\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m--> 730\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor(features)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     pi_features, vf_features \u001b[38;5;241m=\u001b[39m features\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\torch_layers.py:222\u001b[0m, in \u001b[0;36mMlpExtractor.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[th\u001b[38;5;241m.\u001b[39mTensor, th\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    :return: latent_policy, latent_value of the specified network.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m        If all layers are shared, then ``latent_policy == latent_value``\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_actor(features), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_critic(features)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\torch_layers.py:225\u001b[0m, in \u001b[0;36mMlpExtractor.forward_actor\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net(features)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,30):\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=\"PPO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.7455078e-03  1.2482116e-05 -1.6275706e-03 -1.6000081e-02\n",
      "  9.2550687e-02  3.7782986e-03  8.5972244e-01 -1.6015018e-03\n",
      "  1.0000000e+00  3.2850321e-02  3.7781638e-03  8.5350341e-01\n",
      " -2.5707902e-03  1.0000000e+00  4.4081330e-01  4.4581941e-01\n",
      "  4.6142203e-01  4.8954940e-01  5.3410190e-01  6.0246003e-01\n",
      "  7.0914775e-01  8.8593036e-01  1.0000000e+00  1.0000000e+00]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m     13\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m bipedalModel\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[1;32m---> 14\u001b[0m     obs, rewards, done, truncated, info\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     15\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\envs\\box2d\\bipedal_walker.py:608\u001b[0m, in \u001b[0;36mBipedalWalker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    605\u001b[0m     terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(state, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\envs\\box2d\\bipedal_walker.py:718\u001b[0m, in \u001b[0;36mBipedalWalker.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(path) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    717\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mpolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor1, points\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m--> 718\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39maapolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, path, obj\u001b[38;5;241m.\u001b[39mcolor1)\n\u001b[0;32m    719\u001b[0m     path\u001b[38;5;241m.\u001b[39mappend(path[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    720\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mpolygon(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, color\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolor2, points\u001b[38;5;241m=\u001b[39mpath, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    722\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# episodes = 5\n",
    "\n",
    "# env = gym.make('BipedalWalker-v3') \n",
    "# env.reset()\n",
    "\n",
    " \n",
    "env =  gym.make('BipedalWalker-v3',  render_mode='human')\n",
    "obs = env.reset()[0]\n",
    "\n",
    "print(obs)\n",
    "\n",
    "for i in range(1000):\n",
    "    action, _states = bipedalModel.predict(obs)\n",
    "    obs, rewards, done, truncated, info= env.step(action)\n",
    "    env.render()\n",
    "\n",
    "print()\n",
    "\n",
    "# for ep in range(episodes):\n",
    "#     obs = env.reset()\n",
    "#     done = False\n",
    "#     total_rewards = 0\n",
    "#     while not done:\n",
    "#         action, _states = model.predict(obs[0])\n",
    "#         print(env.step(action))\n",
    "#         obs, rewards, done, truncated, info = env.step(action)\n",
    "#         done = done or truncated\n",
    "#         total_rewards += rewards\n",
    "#         env.render()\n",
    "#     print(total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
